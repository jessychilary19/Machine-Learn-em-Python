{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e6f505",
   "metadata": {},
   "source": [
    "## CASE DE VENDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb82eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: polars in c:\\users\\je_hi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.33.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\je_hi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\je_hi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\je_hi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5002d87b",
   "metadata": {},
   "source": [
    "#### 1) Qual o total de vendas da categoria de refrigerantes no mês de maio de 2025?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e09385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\je_hi\\AppData\\Local\\Temp\\ipykernel_9648\\4173633998.py:7: DeprecationWarning: the argument `dtypes` for `read_csv` is deprecated. It was renamed to `schema_overrides` in version 0.20.31.\n",
      "  df_produtos = pl.read_csv(\n",
      "C:\\Users\\je_hi\\AppData\\Local\\Temp\\ipykernel_9648\\4173633998.py:30: DeprecationWarning: the argument `dtypes` for `read_csv` is deprecated. It was renamed to `schema_overrides` in version 0.20.31.\n",
      "  df_vendas = pl.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produtos refrigerantes encontrados: 4500\n",
      "Total de vendas de refrigerantes em maio/2025:\n",
      "shape: (1, 2)\n",
      "┌───────────────────┬────────────────┐\n",
      "│ VENDA_VALOR_TOTAL ┆ UNIDADES_TOTAL │\n",
      "│ ---               ┆ ---            │\n",
      "│ f64               ┆ f64            │\n",
      "╞═══════════════════╪════════════════╡\n",
      "│ 7.1059e11         ┆ 1.2919e11      │\n",
      "└───────────────────┴────────────────┘\n",
      "Salvo em resultado_refrigerantes_maio2025.csv\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "caminho_produtos = r'C:\\\\Users\\\\je_hi\\\\OneDrive\\\\Área de Trabalho\\\\SCANNTECH\\\\BR_PRD_202503_CASE.csv'\n",
    "caminho_vendas   = r'C:\\\\Users\\\\je_hi\\\\OneDrive\\\\Área de Trabalho\\\\SCANNTECH\\\\BR_VTA_202505_CASE.csv'\n",
    "\n",
    "# --- Ler produtos como string ---\n",
    "df_produtos = pl.read_csv(\n",
    "    caminho_produtos,\n",
    "    separator=';',\n",
    "    dtypes={\n",
    "        \"PROD_ID\": pl.Utf8,\n",
    "        \"CATEGORIA\": pl.Utf8\n",
    "    }\n",
    ")\n",
    "\n",
    "# Normalizar PROD_ID e CATEGORIA\n",
    "df_produtos = df_produtos.with_columns([\n",
    "    pl.col(\"PROD_ID\").str.strip_chars().str.to_lowercase(),\n",
    "    pl.col(\"CATEGORIA\").str.strip_chars().str.to_lowercase()\n",
    "])\n",
    "\n",
    "# Filtrar refrigerantes\n",
    "refri_ids = df_produtos.filter(\n",
    "    pl.col(\"CATEGORIA\").str.contains(\"refrig\")\n",
    ")[\"PROD_ID\"].to_list()\n",
    "\n",
    "print(f\"Produtos refrigerantes encontrados: {len(refri_ids)}\")\n",
    "\n",
    "# --- Ler vendas ---\n",
    "df_vendas = pl.read_csv(\n",
    "    caminho_vendas,\n",
    "    separator=';',\n",
    "    columns=['MES', 'PROD_ID', 'VENDA_VALOR', 'UNIDADES'],\n",
    "    dtypes={\n",
    "        \"PROD_ID\": pl.Utf8,\n",
    "        \"MES\": pl.Int64  # MES como número\n",
    "    }\n",
    ")\n",
    "\n",
    "# Normalizar PROD_ID\n",
    "df_vendas = df_vendas.with_columns([\n",
    "    pl.col(\"PROD_ID\").str.strip_chars()\n",
    "])\n",
    "\n",
    "# Função para converter string BR para float\n",
    "def str_to_float(col):\n",
    "    return col.str.replace_all(r'\\.', '').str.replace_all(',', '.').cast(pl.Float64)\n",
    "\n",
    "df_vendas = df_vendas.with_columns([\n",
    "    str_to_float(pl.col(\"VENDA_VALOR\")).alias(\"VENDA_VALOR\"),\n",
    "    str_to_float(pl.col(\"UNIDADES\")).alias(\"UNIDADES\")\n",
    "])\n",
    "\n",
    "# Filtrar só refrigerantes e mês 202505\n",
    "df_refri_maio = df_vendas.filter(\n",
    "    (pl.col(\"MES\") == 202505) &\n",
    "    (pl.col(\"PROD_ID\").is_in(refri_ids))\n",
    ")\n",
    "\n",
    "# Agrupar e somar\n",
    "resultado = df_refri_maio.select([\n",
    "    pl.sum(\"VENDA_VALOR\").alias(\"VENDA_VALOR_TOTAL\"),\n",
    "    pl.sum(\"UNIDADES\").alias(\"UNIDADES_TOTAL\")\n",
    "])\n",
    "\n",
    "print(\"Total de vendas de refrigerantes em maio/2025:\")\n",
    "print(resultado)\n",
    "\n",
    "# Salvar resultado\n",
    "resultado.write_csv(\"resultado_refrigerantes_maio2025.csv\")\n",
    "print(\"Salvo em resultado_refrigerantes_maio2025.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff586f",
   "metadata": {},
   "source": [
    "#### 2) Qual o total de vendas (valor e unidades) do refrigerante de Cola, lata 269ML, da marca Chilly Recommendation nas lojas da Rede Alfa em Betim?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c778a149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\je_hi\\AppData\\Local\\Temp\\ipykernel_9648\\409226817.py:9: DeprecationWarning: the argument `dtypes` for `read_csv` is deprecated. It was renamed to `schema_overrides` in version 0.20.31.\n",
      "  df_produtos = pl.read_csv(\n",
      "C:\\Users\\je_hi\\AppData\\Local\\Temp\\ipykernel_9648\\409226817.py:43: DeprecationWarning: the argument `dtypes` for `read_csv` is deprecated. It was renamed to `schema_overrides` in version 0.20.31.\n",
      "  df_pdv = pl.read_csv(\n",
      "C:\\Users\\je_hi\\AppData\\Local\\Temp\\ipykernel_9648\\409226817.py:61: DeprecationWarning: the argument `dtypes` for `read_csv` is deprecated. It was renamed to `schema_overrides` in version 0.20.31.\n",
      "  df_vendas = pl.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produtos encontrados: 1\n",
      "PDVs encontrados: 87\n",
      "Resultado final:\n",
      "shape: (1, 2)\n",
      "┌───────────────────┬────────────────┐\n",
      "│ VENDA_VALOR_TOTAL ┆ UNIDADES_TOTAL │\n",
      "│ ---               ┆ ---            │\n",
      "│ f64               ┆ f64            │\n",
      "╞═══════════════════╪════════════════╡\n",
      "│ 1.5331e6          ┆ 278415.0       │\n",
      "└───────────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Caminhos\n",
    "caminho_produtos = r'C:\\\\Users\\\\je_hi\\\\OneDrive\\\\Área de Trabalho\\\\SCANNTECH\\\\BR_PRD_202503_CASE.csv'\n",
    "caminho_vendas   = r'C:\\\\Users\\\\je_hi\\\\OneDrive\\\\Área de Trabalho\\\\SCANNTECH\\\\BR_VTA_202505_CASE.csv'\n",
    "caminho_pdv      = r'C:\\\\Users\\\\je_hi\\\\OneDrive\\\\Área de Trabalho\\\\SCANNTECH\\\\BR_PDV_202505_CASE.csv'\n",
    "\n",
    "# --- Produtos ---\n",
    "df_produtos = pl.read_csv(\n",
    "    caminho_produtos,\n",
    "    separator=';',\n",
    "    dtypes={\n",
    "        \"PROD_ID\": pl.Utf8,\n",
    "        \"CLASIFICACAO_5\": pl.Utf8,\n",
    "        \"CLASIFICACAO_9\": pl.Utf8,\n",
    "        \"CLASIFICACAO_10\": pl.Utf8,\n",
    "        \"MARCA\": pl.Utf8,\n",
    "        \"CATEGORIA\": pl.Utf8\n",
    "    }\n",
    ")\n",
    "\n",
    "df_produtos = df_produtos.with_columns([\n",
    "    pl.col(\"PROD_ID\").str.strip_chars().str.to_lowercase(),\n",
    "    pl.col(\"CLASIFICACAO_5\").str.strip_chars().str.to_lowercase(),\n",
    "    pl.col(\"CLASIFICACAO_9\").str.strip_chars().str.to_lowercase(),\n",
    "    pl.col(\"CLASIFICACAO_10\").str.strip_chars().str.to_lowercase(),\n",
    "    pl.col(\"MARCA\").str.strip_chars().str.to_lowercase(),\n",
    "    pl.col(\"CATEGORIA\").str.strip_chars().str.to_lowercase()\n",
    "])\n",
    "\n",
    "# Filtrar produto específico\n",
    "refri_ids = df_produtos.filter(\n",
    "    (pl.col(\"CATEGORIA\").str.contains(\"refrig\")) &\n",
    "    (pl.col(\"MARCA\").str.contains(\"chilly recommendation\")) &\n",
    "    (pl.col(\"CLASIFICACAO_5\").str.contains(\"lata\")) &\n",
    "    (pl.col(\"CLASIFICACAO_9\").str.contains(\"cola\")) &\n",
    "    (pl.col(\"CLASIFICACAO_10\").str.contains(\"269ml\"))\n",
    ")[\"PROD_ID\"].to_list()\n",
    "\n",
    "print(f\"Produtos encontrados: {len(refri_ids)}\")\n",
    "\n",
    "# --- PDVs ---\n",
    "df_pdv = pl.read_csv(\n",
    "    caminho_pdv,\n",
    "    separator=';',\n",
    "    dtypes={\n",
    "        \"PDV_ID\": pl.Utf8,\n",
    "        \"REDE\": pl.Utf8,\n",
    "        \"LOCAL\": pl.Utf8\n",
    "    }\n",
    ")\n",
    "\n",
    "pdv_ids = df_pdv.filter(\n",
    "    (pl.col(\"REDE\").str.contains(\"REDE ALFA\")) &\n",
    "    (pl.col(\"LOCAL\").str.contains(\"BETIM\"))\n",
    ")[\"PDV_ID\"].to_list()\n",
    "\n",
    "print(f\"PDVs encontrados: {len(pdv_ids)}\")\n",
    "\n",
    "# --- Vendas ---\n",
    "df_vendas = pl.read_csv(\n",
    "    caminho_vendas,\n",
    "    separator=';',\n",
    "    columns=['MES', 'PROD_ID', 'PDV_ID', 'VENDA_VALOR', 'UNIDADES'],\n",
    "    dtypes={\n",
    "        \"PROD_ID\": pl.Utf8,\n",
    "        \"PDV_ID\": pl.Utf8,\n",
    "        \"MES\": pl.Int64\n",
    "    }\n",
    ")\n",
    "\n",
    "df_vendas = df_vendas.with_columns([\n",
    "    pl.col(\"PROD_ID\").str.strip_chars(),\n",
    "    pl.col(\"PDV_ID\").str.strip_chars()\n",
    "])\n",
    "\n",
    "# Conversão valores BR\n",
    "def str_to_float(col):\n",
    "    return col.str.replace_all(r'\\.', '').str.replace_all(',', '.').cast(pl.Float64)\n",
    "\n",
    "df_vendas = df_vendas.with_columns([\n",
    "    str_to_float(pl.col(\"VENDA_VALOR\")).alias(\"VENDA_VALOR\"),\n",
    "    str_to_float(pl.col(\"UNIDADES\")).alias(\"UNIDADES\")\n",
    "])\n",
    "\n",
    "# Filtrar produtos e PDVs específicos em maio/2025\n",
    "df_filtrado = df_vendas.filter(\n",
    "    (pl.col(\"MES\") == 202505) &\n",
    "    (pl.col(\"PROD_ID\").is_in(refri_ids)) &\n",
    "    (pl.col(\"PDV_ID\").is_in(pdv_ids))\n",
    ")\n",
    "\n",
    "# Somar valores e unidades\n",
    "resultado = df_filtrado.select([\n",
    "    pl.sum(\"VENDA_VALOR\").alias(\"VENDA_VALOR_TOTAL\"),\n",
    "    pl.sum(\"UNIDADES\").alias(\"UNIDADES_TOTAL\")\n",
    "])\n",
    "\n",
    "print(\"Resultado final:\")\n",
    "print(resultado)\n",
    "\n",
    "# Salvar CSV\n",
    "resultado.write_csv(\"resultado_produto_loja_maio2025.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d570cd",
   "metadata": {},
   "source": [
    "\n",
    "#### 3) Quais foram os 3 fabricantes com maior faturamento no sudeste e qual tipo de loja teve maior representatividade para cada um deles? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adabac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIANDO PROCESSAMENTO...\n",
      "==================================================\n",
      "Lendo produtos...\n",
      "Lendo PDVs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\je_hi\\AppData\\Local\\Temp\\ipykernel_24424\\3486154491.py:14: DeprecationWarning: the argument `dtypes` for `read_csv` is deprecated. It was renamed to `schema_overrides` in version 0.20.31.\n",
      "  df_produtos = pl.read_csv(\n",
      "C:\\Users\\je_hi\\AppData\\Local\\Temp\\ipykernel_24424\\3486154491.py:28: DeprecationWarning: the argument `dtypes` for `read_csv` is deprecated. It was renamed to `schema_overrides` in version 0.20.31.\n",
      "  df_pdv = pl.read_csv(\n",
      "C:\\Users\\je_hi\\AppData\\Local\\Temp\\ipykernel_24424\\3486154491.py:50: DeprecationWarning: the argument `dtypes` for `read_csv` is deprecated. It was renamed to `schema_overrides` in version 0.20.31.\n",
      "  df_vendas = pl.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDVs do Sudeste: 5134\n",
      "Lendo vendas...\n",
      "Convertendo valores...\n",
      "Fazendo joins...\n",
      "Registros após join: 13199628\n",
      "Agrupando por fabricante...\n",
      "Top 3 fabricantes: ['Rodriguez Group', 'Kuhn and Sons', 'Lynch, Watsica and Predovic']\n",
      "Processando fabricante: Rodriguez Group\n",
      "Processando fabricante: Kuhn and Sons\n",
      "Processando fabricante: Lynch, Watsica and Predovic\n",
      "\n",
      " RESULTADO FINAL:\n",
      "==================================================\n",
      "shape: (3, 3)\n",
      "┌─────────────────────────────┬───────────────────┬─────────────────────┐\n",
      "│ FABRICANTE                  ┆ FATURAMENTO_TOTAL ┆ TIPO_LOJA_PRINCIPAL │\n",
      "│ ---                         ┆ ---               ┆ ---                 │\n",
      "│ str                         ┆ f64               ┆ str                 │\n",
      "╞═════════════════════════════╪═══════════════════╪═════════════════════╡\n",
      "│ Rodriguez Group             ┆ 4.7022e9          ┆ Supermercado        │\n",
      "│ Kuhn and Sons               ┆ 3.3187e9          ┆ Supermercado        │\n",
      "│ Lynch, Watsica and Predovic ┆ 3.2561e9          ┆ Supermercado        │\n",
      "└─────────────────────────────┴───────────────────┴─────────────────────┘\n",
      "\n",
      " Resultado salvo em 'top3_fabricantes_sudeste.csv'\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# --- Caminhos dos arquivos ---\n",
    "caminho_produtos = r'C:\\Users\\je_hi\\OneDrive\\Área de Trabalho\\SCANNTECH\\BR_PRD_202503_CASE.csv'\n",
    "caminho_vendas   = r'C:\\Users\\je_hi\\OneDrive\\Área de Trabalho\\SCANNTECH\\BR_VTA_202505_CASE.csv'\n",
    "caminho_pdv      = r'C:\\Users\\je_hi\\OneDrive\\Área de Trabalho\\SCANNTECH\\BR_PDV_202505_CASE.csv'\n",
    "\n",
    "print(\"INICIANDO PROCESSAMENTO...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # --- Ler produtos ---\n",
    "    print(\"Lendo produtos...\")\n",
    "    df_produtos = pl.read_csv(\n",
    "        caminho_produtos,\n",
    "        separator=';',\n",
    "        encoding='utf-8',\n",
    "        dtypes={\n",
    "            \"PROD_ID\": pl.Int64,\n",
    "            \"FABRICANTE\": pl.Utf8\n",
    "        }\n",
    "    ).with_columns([\n",
    "        pl.col(\"FABRICANTE\").str.strip_chars().alias(\"FABRICANTE\")\n",
    "    ])\n",
    "\n",
    "    # --- Ler PDVs ---\n",
    "    print(\"Lendo PDVs...\")\n",
    "    df_pdv = pl.read_csv(\n",
    "        caminho_pdv,\n",
    "        separator=';',\n",
    "        encoding='utf-8',\n",
    "        dtypes={\n",
    "            \"PDV_ID\": pl.Int64,\n",
    "            \"CLASIFICACAO_2\": pl.Utf8,\n",
    "            \"TIPO_LOJA\": pl.Utf8\n",
    "        }\n",
    "    ).with_columns([\n",
    "        pl.col(\"CLASIFICACAO_2\").str.strip_chars().alias(\"CLASIFICACAO_2\"),\n",
    "        pl.col(\"TIPO_LOJA\").str.strip_chars().alias(\"TIPO_LOJA\")\n",
    "    ])\n",
    "\n",
    "    # Filtrar apenas Sudeste\n",
    "    df_pdv_sudeste = df_pdv.filter(\n",
    "        pl.col(\"CLASIFICACAO_2\").str.to_uppercase() == \"SUDESTE\"\n",
    "    )\n",
    "    print(f\"PDVs do Sudeste: {df_pdv_sudeste.shape[0]}\")\n",
    "\n",
    "    # --- Ler vendas ---\n",
    "    print(\"Lendo vendas...\")\n",
    "    df_vendas = pl.read_csv(\n",
    "        caminho_vendas,\n",
    "        separator=';',\n",
    "        encoding='utf-8',\n",
    "        columns=['PROD_ID', 'PDV_ID', 'VENDA_VALOR'],\n",
    "        dtypes={\n",
    "            \"PROD_ID\": pl.Int64,\n",
    "            \"PDV_ID\": pl.Int64,\n",
    "            \"VENDA_VALOR\": pl.Utf8  # Ler como string para converter depois\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Convertendo valores...\")\n",
    "    df_vendas = df_vendas.with_columns([\n",
    "        pl.col(\"VENDA_VALOR\")\n",
    "        .str.replace_all(r\"\\.\", \"\")\n",
    "        .str.replace_all(\",\", \".\")\n",
    "        .cast(pl.Float64)\n",
    "        .alias(\"VENDA_VALOR\")\n",
    "    ])\n",
    "\n",
    "    # --- Join vendas com produtos para pegar FABRICANTE ---\n",
    "    print(\"Fazendo joins...\")\n",
    "    df_join = df_vendas.join(\n",
    "        df_produtos.select(['PROD_ID', 'FABRICANTE']),\n",
    "        on='PROD_ID',\n",
    "        how='left'\n",
    "    ).join(\n",
    "        df_pdv_sudeste.select(['PDV_ID', 'TIPO_LOJA']),\n",
    "        on='PDV_ID',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    print(f\"Registros após join: {df_join.shape[0]}\")\n",
    "\n",
    "    # --- Agrupar por FABRICANTE e somar faturamento ---\n",
    "    print(\"Agrupando por fabricante...\")\n",
    "    faturamento_por_fabricante = df_join.group_by(\"FABRICANTE\").agg(\n",
    "        pl.sum(\"VENDA_VALOR\").alias(\"FATURAMENTO_TOTAL\")\n",
    "    ).sort(\"FATURAMENTO_TOTAL\", descending=True)\n",
    "\n",
    "    # --- Selecionar top 3 fabricantes ---\n",
    "    top3_fabricantes = faturamento_por_fabricante.head(3)[\"FABRICANTE\"].to_list()\n",
    "    print(f\"Top 3 fabricantes: {top3_fabricantes}\")\n",
    "\n",
    "    # --- Para cada fabricante, identificar tipo de loja com maior faturamento ---\n",
    "    resultados = []\n",
    "    for fab in top3_fabricantes:\n",
    "        print(f\"Processando fabricante: {fab}\")\n",
    "        tipo_loja_sum = (\n",
    "            df_join.filter(pl.col(\"FABRICANTE\") == fab)\n",
    "            .group_by(\"TIPO_LOJA\")\n",
    "            .agg(pl.sum(\"VENDA_VALOR\").alias(\"FATURAMENTO_TIPO\"))\n",
    "            .sort(\"FATURAMENTO_TIPO\", descending=True)\n",
    "        )\n",
    "        \n",
    "        if tipo_loja_sum.height > 0:\n",
    "            top_tipo_loja = tipo_loja_sum[0, \"TIPO_LOJA\"]\n",
    "            faturamento_total = faturamento_por_fabricante.filter(\n",
    "                pl.col(\"FABRICANTE\") == fab\n",
    "            )[\"FATURAMENTO_TOTAL\"][0]\n",
    "\n",
    "            resultados.append({\n",
    "                \"FABRICANTE\": fab,\n",
    "                \"FATURAMENTO_TOTAL\": faturamento_total,\n",
    "                \"TIPO_LOJA_PRINCIPAL\": top_tipo_loja\n",
    "            })\n",
    "\n",
    "    # --- Criar DataFrame final ---\n",
    "    df_resultado_final = pl.DataFrame(resultados)\n",
    "    \n",
    "    print(\"\\n RESULTADO FINAL:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(df_resultado_final)\n",
    "\n",
    "    # --- Salvar resultado ---\n",
    "    df_resultado_final.write_csv(\"top3_fabricantes_sudeste.csv\")\n",
    "    print(\"\\n Resultado salvo em 'top3_fabricantes_sudeste.csv'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Erro: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc219a",
   "metadata": {},
   "source": [
    "#### 4) Qual sua sugestão de melhoria na estrutura dos arquivos, visando performance e clareza dos dados?\n",
    "####\n",
    "Durante o trabalho realizado tive dificuldades para processar todos os dados da planilha de vendas, que atualmente possui mais de **25 milhões de linhas**.  \n",
    "\n",
    "#### Substituir CSV por formatos colunares (Parquet/Feather)\n",
    "- O **CSV** é pesado para leitura, ocupa mais espaço em disco e não possui compressão nativa eficiente.  \n",
    "- Formatos colunares como **Parquet** ou **Feather** (suportados por **Polars** e **Power BI**) oferecem:\n",
    "  - Redução significativa do tamanho dos arquivos  \n",
    "  - Maior velocidade de leitura  \n",
    "  - Leitura seletiva apenas das colunas necessárias  \n",
    "\n",
    "Exemplo em **Polars**:\n",
    "```python\n",
    "df.write_parquet(\"vendas.parquet\", compression=\"snappy\")\n",
    "\n",
    "Outro ponto que pode gerar conflito de informações é com relação ao mês que está sendo analisado na tabela de Vendas tem a coluna MES  e na tabela Produto tem a coluna Data_Promoção."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca9c9e",
   "metadata": {},
   "source": [
    "#### 5) Como você faria para estruturar a disponibilização das informações contidas nos arquivos em uma API REST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c57ed401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'produtos.json' criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "\n",
    "# Caminho do CSV\n",
    "caminho_csv = r'C:\\Users\\je_hi\\OneDrive\\Área de Trabalho\\SCANNTECH\\BR_PRD_202503_CASE.csv'\n",
    "\n",
    "# Ler CSV \n",
    "df = pl.read_csv(caminho_csv, separator=\";\")\n",
    "\n",
    "# Converter para lista de dicionários\n",
    "lista_dicts = df.to_dicts()\n",
    "\n",
    "# Salvar em JSON\n",
    "with open(\"produtos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(lista_dicts, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Arquivo 'produtos.json' criado com sucesso!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9d116a",
   "metadata": {},
   "source": [
    "Eu faria a disponibilização das informações em uma API REST utilizando Flask (ou outro framework web em Python). A ideia é organizar os dados dos arquivos em endpoints que seguem boas práticas RESTful.\n",
    "\n",
    "Estrutura do projeto\n",
    "\n",
    "main.py: código principal da API\n",
    "\n",
    "produtos.json: armazenamento dos dados (simulando um banco de dados)\n",
    "\n",
    "requirements.txt: dependências\n",
    "\n",
    "Procfile: configuração para deploy (Railway/Heroku)\n",
    "\n",
    "Rotas principais da API\n",
    "\n",
    "GET /produtos → retorna todos os produtos contidos no arquivo produtos.json\n",
    "\n",
    "POST /produtos → recebe um JSON no corpo da requisição e adiciona um novo produto no arquivo\n",
    "\n",
    "(opcionalmente poderíamos ter GET /produtos/<id>, PUT /produtos/<id>, DELETE /produtos/<id> para operações completas de CRUD)\n",
    "\n",
    "Formato de dados\n",
    "As respostas são retornadas em JSON, que é o padrão para APIs REST.\n",
    "Exemplo de resposta:\n",
    "\n",
    "[\n",
    "    {\"id\": 1, \"nome\": \"Arroz\", \"preco\": 12.50},\n",
    "    {\"id\": 2, \"nome\": \"Feijão\", \"preco\": 8.90}\n",
    "]\n",
    "\n",
    "\n",
    "Deploy em nuvem\n",
    "\n",
    "Usei o Railway para hospedar a API.\n",
    "\n",
    "O servidor é iniciado com gunicorn main:app (onde main é o nome do arquivo e app a aplicação Flask).\n",
    "\n",
    "A API ficou disponível publicamente em uma URL, permitindo o consumo remoto.\n",
    "\n",
    "Link da API: https://web-production-ff7fe.up.railway.app/produtos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd7000",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
